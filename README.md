>Machine Learning INFO5 2024-2025 **ISPM**
# QUICKSILVER ü§ñ

# Th√®me : Traitement-Automatique-Langage-Naturel

## Institut Sup√©rieur Polytechnique de Madagascar : http://www.ispm-edu.com/
Membre de l'√©quipe (IGGLIA 5) et le r√¥le respectif de chacun: 
  * **RANDRIANOELINA Liantsoa Harimisa                       ,n¬∞14** : charg√© de la recherche du dataset et nettoyage des donn√©es + d√©ploiement.
  * **ZAFIARISON Koloina Emile                               ,n¬∞16** : charg√© de l'int√©gration front et d√©veloppement endpoint pour faire la pr√©diction + d√©ploiement.
  * **RANDIMBINIRINA RAKOTOMANANA Yusha Andry Ny Aina        ,n¬∞19** : charg√© du d√©veloppement du pipeline de pr√©-traitement des textes + d√©ploiement.
  * **RASOLONJATOVO Zo Heriniaina                            ,n¬∞23** : charg√© de l'entrainement du mod√®le et les tests  + d√©ploiement.

## ‚öíÔ∏è Stack Technologique :
  * Front : Next js

    Choisi pour sa rapidit√© et sa flexibilit√© dans la cr√©ation d‚Äôinterfaces web modernes et r√©actives.
    Permet d‚Äôafficher les r√©sultats de la d√©tection de spam/ham en temps r√©el et d‚Äôoffrir une exp√©rience utilisateur fluide.

  * Mod√®le ML : Python

    Nous avons choisi Python car c'etait impos√© et de plus il fournit d√©j√† des biblioth√®ques qui facilitent et optimisent l'impl√©mentation et la performance du mod√®le.
   
  * Backend : Django

    Utilis√© pour g√©rer la logique serveur,la communication entre le front-end et le mod√®le de machine learning.
    Permet de faciliter le d√©ploiement de l‚Äôapplication.

## ‚öôÔ∏è Description du processus :
   * PIPELINE DE PRE-TRAITEMENT : TF-IDF et N-GRAM (Bigram)

Nous avons choisi d‚Äôutiliser TF-IDF plut√¥t que Bag-of-Words car elle met davantage en valeur les mots rares et discriminants tout en r√©duisant l‚Äôinfluence des mots fr√©quents et peu informatifs.
Nous avons √©galement utilis√© des bigrammes afin de capturer non seulement les mots individuels, mais aussi les combinaisons de deux mots cons√©cutifs, ce qui permet au mod√®le de mieux identifier les expressions typiques du spam et d‚Äôam√©liorer la pr√©cision de la classification.

## üîÅ M√©thode ML et mod√®le : RANDOM FOREST 
Nous avons initialement utilis√© Logistic Regression, car elle r√©duit le risque de surapprentissage sur un petit dataset. Cependant, apr√®s comparaison des r√©sultats, nous avons opt√© pour Random Forest, car elle permet de r√©duire les faux n√©gatifs, rendant le mod√®le plus fiable pour la d√©tection des messages spam. Par cons√©quent, nous avons entra√Æn√© une instance de Random Forest qui constitue le mod√®le concret utilis√© pour pr√©dire si un message est spam ou non.


## üìä Datasets Utilis√©s : 
On a r√©cup√©r√© notre dataset sur HuggingFace (https://huggingface.co/datasets/dbarbedillo/SMS_Spam_Multilingual_Collection_Dataset), mais il √©tait multilingue, donc on a seulement r√©cup√©r√© les colonnes des textes en fran√ßais ainsi que le label qui d√©tecte si le texte est un ham ou spam. 

## üåê Lien vers l‚Äôapplication web h√©berg√©e : https://frontent-tp-machine-learning-30-01.vercel.app/
## üåê Lien vers le Back-End de l'application : https://github.com/HeriniainaRas/Backend-Automatic-Processing-Natural-Language
